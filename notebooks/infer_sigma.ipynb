{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "130cbaef",
   "metadata": {},
   "source": [
    "# Implied Volatility Inference with JAX\n",
    "\n",
    "This notebook demonstrates how to recover (\"invert\") the implied volatility of a European vanilla option using:\n",
    "\n",
    "- Black–Scholes pricing implemented in JAX\n",
    "- Automatic differentiation to obtain Vega (gradient wrt volatility)\n",
    "- Newton–Raphson root-finding\n",
    "\n",
    "We will:\n",
    "1. Price a synthetic option and recover its volatility.\n",
    "2. Compare autodiff Vega vs. analytic Vega.\n",
    "3. Visualize the loss function and Newton iterations.\n",
    "4. (Optional) Pull a real option chain with `yfinance` and compute a mini volatility smile.\n",
    "\n",
    "> Educational, work-in-progress. Not production code or trading advice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72407b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.model.main import black_scholes, NR_for_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77527104",
   "metadata": {},
   "source": [
    "Using Newton–Raphson and `jax.grad` to compute implied (\"intrinsic\") volatility.\n",
    "\n",
    "Given a market option premium C_mkt we solve for σ such that:\n",
    "\n",
    "BlackScholes(S, K, T, r, σ, q, otype) = C_mkt\n",
    "\n",
    "Define f(σ) = model_price(σ) - C_mkt. Newton step:\n",
    "\n",
    "σ_{n+1} = σ_n - f(σ_n) / f'(σ_n)\n",
    "\n",
    "Here f'(σ) (Vega) is supplied by automatic differentiation instead of a manually coded analytic derivative.\n",
    "\n",
    "We will later:\n",
    "- Compare autodiff Vega vs closed-form Vega\n",
    "- Plot f(σ) to visualize curvature and convergence behavior\n",
    "- Extend to multiple strikes from a real option chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61b81c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-09-16 13:47:53,905:jax._src.xla_bridge:864: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.040088129724232\n"
     ]
    }
   ],
   "source": [
    "S, K, T, r, q = 100, 110, 1, 0.05, 0.0\n",
    "otype = \"call\"\n",
    "\n",
    "true_sigma = 0.2\n",
    "market_price = black_scholes(S, K, T, r, true_sigma, q, otype)\n",
    "print(market_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fda5953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: sigma=0.3, loss=3.979989490331725\n",
      "Iter 1: sigma=0.20023640478353788, loss=0.00935619522458353\n",
      "Iter 2: sigma=0.20000000575577456, loss=2.2779081376711474e-07\n",
      "Iter 3: sigma=0.19999999999999993, loss=7.105427357601002e-15\n",
      "\n",
      "Inferred sigma: 0.19999999999999993\n",
      "True sigma: 0.2\n"
     ]
    }
   ],
   "source": [
    "inferred_sigma = NR_for_sigma(\n",
    "    S,\n",
    "    K,\n",
    "    T,\n",
    "    r,\n",
    "    market_price,\n",
    "    sigma_guess=0.3,\n",
    "    q=q,\n",
    "    otype=otype,\n",
    "    tol=1e-7,\n",
    "    max_iter=100,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(f\"Inferred sigma: {inferred_sigma}\")\n",
    "print(f\"True sigma: {true_sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c8043",
   "metadata": {},
   "source": [
    "### Analytic Vega vs Autodiff\n",
    "We'll add the closed-form Vega and compare it to the gradient produced by JAX to ensure correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95217175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Analytic Black-Scholes Vega (undiscounted form times discount factors)\n",
    "# Vega = S * exp(-q T) * phi(d1) * sqrt(T)\n",
    "\n",
    "def analytic_vega(S, K, T, r, sigma, q=0.0):\n",
    "    d1 = (jnp.log(S / K) + (r - q + 0.5 * sigma**2) * T) / (sigma * jnp.sqrt(T))\n",
    "    pdf = 1.0 / jnp.sqrt(2 * jnp.pi) * jnp.exp(-0.5 * d1**2)\n",
    "    return S * jnp.exp(-q * T) * pdf * jnp.sqrt(T)\n",
    "\n",
    "# Use autodiff on model price directly for comparison\n",
    "price_wrt_sigma = jax.grad(lambda sig: black_scholes(S, K, T, r, sig, q, otype))\n",
    "\n",
    "vega_ad = price_wrt_sigma(true_sigma)\n",
    "vega_analytic = analytic_vega(S, K, T, r, true_sigma, q)\n",
    "\n",
    "print(f\"Autodiff Vega:  {vega_ad}\")\n",
    "print(f\"Analytic Vega:  {vega_analytic}\")\n",
    "print(f\"Abs diff:       {jnp.abs(vega_ad - vega_analytic)}\")\n",
    "print(f\"Rel diff:       {jnp.abs(vega_ad - vega_analytic) / vega_analytic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1d503",
   "metadata": {},
   "source": [
    "### Visualizing the Loss Function and Newton Steps\n",
    "We'll sample the loss over a grid of sigma values and overlay the Newton iterates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture Newton iterations manually for plotting\n",
    "\n",
    "sig0 = 0.30\n",
    "sig_iter = []\n",
    "loss_iter = []\n",
    "\n",
    "sigma = sig0\n",
    "for i in range(12):  # hard cap\n",
    "    f = (black_scholes(S, K, T, r, sigma, q, otype) - market_price)\n",
    "    sig_iter.append(float(sigma))\n",
    "    loss_iter.append(float(f))\n",
    "    if jnp.abs(f) < 1e-8:\n",
    "        break\n",
    "    vega = jax.grad(lambda s: black_scholes(S, K, T, r, s, q, otype))(sigma)\n",
    "    sigma = sigma - f / vega\n",
    "\n",
    "# Grid for visualization\n",
    "sig_grid = jnp.linspace(0.05, 0.60, 200)\n",
    "loss_grid = black_scholes(S, K, T, r, sig_grid, q, otype) - market_price\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].plot(sig_grid, loss_grid, label='loss(sigma)')\n",
    "ax[0].axhline(0, color='k', lw=0.7)\n",
    "ax[0].scatter(sig_iter, loss_iter, color='red', zorder=5, label='Newton path')\n",
    "for i,(s,l) in enumerate(zip(sig_iter, loss_iter)):\n",
    "    ax[0].annotate(str(i), (s,l), textcoords=\"offset points\", xytext=(4,4), fontsize=8)\n",
    "ax[0].set_xlabel('sigma')\n",
    "ax[0].set_ylabel('loss')\n",
    "ax[0].legend()\n",
    "\n",
    "price_grid = black_scholes(S, K, T, r, sig_grid, q, otype)\n",
    "ax[1].plot(sig_grid, price_grid, label='Price(sigma)')\n",
    "ax[1].axhline(float(market_price), color='k', lw=0.7, linestyle='--', label='Market price')\n",
    "ax[1].scatter([true_sigma],[float(market_price)], color='green', label='True sigma')\n",
    "ax[1].scatter(sig_iter, black_scholes(S,K,T,r,jnp.array(sig_iter), q, otype), color='red', s=20)\n",
    "ax[1].set_xlabel('sigma')\n",
    "ax[1].set_ylabel('Option Price')\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23f487",
   "metadata": {},
   "source": [
    "### Mini Option Chain Example\n",
    "Fetch a live chain (AAPL by default), take a small subset, and compute implied vols for mid prices (illustrative only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader.main import get_option_chain\n",
    "\n",
    "try:\n",
    "    chain = get_option_chain(\"AAPL\", clean=True)\n",
    "    display(chain.head())\n",
    "except Exception as e:\n",
    "    print(\"Failed to load option chain:\", e)\n",
    "    chain = None\n",
    "\n",
    "# Select a slice: near-the-money calls with first expiry\n",
    "if chain is not None and not chain.empty:\n",
    "    first_exp = chain['expiry'].min()\n",
    "    sub = chain[(chain['expiry']==first_exp) & (chain['otype']=='call')].copy()\n",
    "    sub = sub.sort_values('K').head(8)  # small sample\n",
    "    results = []\n",
    "    for _, row in sub.iterrows():\n",
    "        S_row = float(row['spot'])\n",
    "        K_row = float(row['K'])\n",
    "        T_row = float(row['T'])\n",
    "        mid = float(row['mid'])\n",
    "        # crude guess for sigma\n",
    "        guess = 0.25\n",
    "        try:\n",
    "            impl = NR_for_sigma(S_row, K_row, T_row, r=0.05, market_price=mid, sigma_guess=guess, q=0.0, otype='call', tol=1e-6, max_iter=100)\n",
    "            results.append({\"K\":K_row, \"T\":T_row, \"mid\":mid, \"implied_vol\": float(impl)})\n",
    "        except Exception as err:\n",
    "            results.append({\"K\":K_row, \"T\":T_row, \"mid\":mid, \"implied_vol\": float('nan')})\n",
    "    iv_df = pd.DataFrame(results)\n",
    "    display(iv_df)\n",
    "\n",
    "    # Simple smile plot\n",
    "    if not iv_df.empty:\n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.plot(iv_df['K'], iv_df['implied_vol'], marker='o')\n",
    "        plt.xlabel('Strike')\n",
    "        plt.ylabel('Implied Vol')\n",
    "        plt.title('Mini Call Smile (First Expiry)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51f78e",
   "metadata": {},
   "source": [
    "### Wrap-Up\n",
    "We demonstrated:\n",
    "- Autodiff-based Vega matches analytic Vega closely\n",
    "- Newton–Raphson converges rapidly with a reasonable initial guess\n",
    "- Visual diagnostics (loss curve) help understand convergence\n",
    "- Extension to a small live option chain to build an embryonic smile\n",
    "\n",
    "Next steps (future work): batch vectorized IV surface, robustness improvements (fallback solvers), and performance benchmarking of autodiff vs analytic Greeks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
